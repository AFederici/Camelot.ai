{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use something called variational inference to recover clean versions of a series of simple, 3-color images which have been perturbed with random noise. As a grandmaster module, the problems here will likely introduce new concepts, but we'll provide all the tools you need to learn along the way.\n",
    "\n",
    "Every image pixel is a node in an undirected graph, with all neighboring nodes connected by an edge. Each pixel can take one of K=3 values (0-Red, 1-Green, and 2-Blue), and we wish to uncover its true value, given the observed, noisy value. Only pixels (nodes) connected by an edge influence each other's values. In other words, knowing the value of a pixel in the top-right corner doesn't give us any information about the value of a pixel in the bottom-right corner, but knowing the value of an adjacent pixel tells us a lot about any given pixel.\n",
    "\n",
    "Each node and edge in this graph has an associated weight or \"potential,\" which indicates our beliefs about (1) how likely a node is a given color based on its observed value, and (2) whether a given pair of neighboring node colors are likely to occur together. For instance, we may believe that neighboring nodes are more likely to be similar colors than different colors--this property is called image smoothness. Thus, we can de-noise an image by setting each pixel to be the color that is most likely, given the colors of its neighbors.\n",
    "\n",
    "First, implement the helper function neighbors, which should take in the coordinates (row, column) of a pixel and the dimensions of the image and print all valid adjacent pixel coordinates, in clockwise order, starting from the pixel directly to the left of the target. Each neighbor should be printed on a separate line, and the two coordinates of a pixel should be space-separated.\n",
    "```\n",
    "Example 1:\n",
    "Input:  \n",
    "i = 0   # row index\n",
    "j = 0   # column index\n",
    "N = 10  # total number of rows\n",
    "M = 12  # total number of columns\n",
    "\n",
    "Output: \n",
    "0 1\n",
    "1 0\n",
    "```\n",
    "Explanation: There is no pixel directly to the left, or directly above (0, 0), which is at the top-left of the image. Thus, we only print the pixel to its right, followed by the pixel below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighbors(self, i, j, N, M):\n",
    "    #left,up,right,down\n",
    "    #i,j  row, column\n",
    "    if N > 0 and M > 0:\n",
    "        if j - 1 >= 0 and j - 1 < M:\n",
    "            if j-1 != j:\n",
    "                print (i, j-1)\n",
    "        if i - 1 >= 0 and i - 1 < N:\n",
    "            if i-1 != i:\n",
    "                print (i - 1, j)\n",
    "        if j + 1 >= 0 and j + 1 < M:\n",
    "            if j+1 != j:\n",
    "                print (i, j +1)\n",
    "        if i + 1 >= 0 and i + 1 < N:\n",
    "            if i+1 != i:\n",
    "                print (i +1, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our images have dimensions N x M x 3, where the first two dimensions indicate the pixel row and column, and the last dimension is a vector encoding the color. This vector at each pixel (i, j) sums to 1 and can be thought of as representing a probability distribution over the colors Red, Green, and Blue. For example, a vector of (1, 0, 0) denotes pure red, while (0, 1, 0) denotes pure green. To de-noise images, we'll calculate approximations of the true distributions at each pixel. However, these raw approximations may not be normalized to sum to 1. Let's implement a function to do this.\n",
    "\n",
    "The softmax function compresses an n-dimensional vector so that each element is in the range [0, 1], and all the elements sum to 1 (i.e., it outputs a categorical distribution). It first exponentiates each element, and then normalizes the resulting vector by dividing by the sum. However, a naive implementation of this could be prone to numerical underflow (e^(-1000)) or overflow (e^1000).\n",
    "\n",
    "Write the helper function softmax to normalize a vector (given as an array), truncating all floats to 4 digits after the decimal point. Your function should be robust to very large or small vector values. Print out the normalized vector on one line, separated by spaces.\n",
    "```\n",
    "Example 1:\n",
    "Input:  \n",
    "x = [0, 1, 2]\n",
    "\n",
    "Output: \n",
    "0.0900 0.2447 0.6652 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(self, x):\n",
    "    shiftx = x - np.max(x)\n",
    "    exps = np.exp(shiftx)\n",
    "    value = exps / np.sum(exps)\n",
    "    print(' '.join([ \"{:.4f}\".format(e) for e in value ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
